#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLM API å‘¼å«æ¸¬è©¦ç¨‹å¼
åƒè€ƒ curl æŒ‡ä»¤å»ºç«‹å°æ‡‰çš„ Python å¯¦ä½œ
"""

import requests
import json
import time
from typing import Dict, List, Optional


class LLMAPI:
    """LLM API å‘¼å«é¡åˆ¥"""
    
    def __init__(self, base_url: str, api_key: str):
        """
        åˆå§‹åŒ– LLM API å®¢æˆ¶ç«¯
        
        Args:
            base_url: API åŸºç¤ URL
            api_key: API é‡‘é‘°
        """
        self.base_url = base_url.rstrip('/')
        self.api_key = api_key
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "ngrok-skip-browser-warning": "true"
        }
    
    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "gpt-oss-120b",
        temperature: float = 0.7,
        stream: bool = False
    ) -> Dict:
        """
        ç™¼é€èŠå¤©å®Œæˆè«‹æ±‚
        
        Args:
            messages: è¨Šæ¯åˆ—è¡¨ï¼Œæ ¼å¼ç‚º [{"role": "user", "content": "..."}]
            model: ä½¿ç”¨çš„æ¨¡å‹åç¨±
            temperature: æº«åº¦åƒæ•¸ï¼Œæ§åˆ¶å›æ‡‰çš„éš¨æ©Ÿæ€§
            stream: æ˜¯å¦ä½¿ç”¨ä¸²æµæ¨¡å¼
            
        Returns:
            API å›æ‡‰çš„å­—å…¸
        """
        url = f"{self.base_url}/chat/completions"
        
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream
        }
        
        try:
            print(f"ç™¼é€è«‹æ±‚åˆ°: {url}")
            print(f"è«‹æ±‚æ¨™é ­: {json.dumps(dict(self.headers), ensure_ascii=False, indent=2)}")
            print(f"è«‹æ±‚å…§å®¹: {json.dumps(payload, ensure_ascii=False, indent=2)}")
            
            # ngrok é ç†±æ©Ÿåˆ¶ï¼šå…ˆç™¼é€ GET è«‹æ±‚ä¾†å–šé†’æœå‹™
            print("ğŸ”„ ngrok é ç†±ä¸­...")
            try:
                warmup_response = requests.get(
                    self.base_url,
                    headers={"ngrok-skip-browser-warning": "true"},
                    timeout=5
                )
                print(f"   é ç†± GET è«‹æ±‚ç‹€æ…‹ç¢¼: {warmup_response.status_code}")
                time.sleep(0.5)  # ç¨å¾®ç­‰å¾…ä¸€ä¸‹è®“é€£ç·šç©©å®š
            except Exception as e:
                print(f"   é ç†±è«‹æ±‚å¤±æ•— (å¯å¿½ç•¥): {e}")
            
            print("ğŸ“¤ ç™¼é€ä¸»è¦ POST è«‹æ±‚...")
            response = requests.post(
                url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            print(f"å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
            print(f"å›æ‡‰æ¨™é ­: {dict(response.headers)}")
            
            if response.status_code == 200:
                result = response.json()
                print(f"å›æ‡‰å…§å®¹: {json.dumps(result, ensure_ascii=False, indent=2)}")
                return result
            else:
                print(f"éŒ¯èª¤å›æ‡‰ç‹€æ…‹ç¢¼: {response.status_code}")
                print(f"éŒ¯èª¤å›æ‡‰å…§å®¹: {response.text}")
                print(f"éŒ¯èª¤å›æ‡‰æ¨™é ­: {dict(response.headers)}")
                return {"error": response.status_code, "message": response.text}
                
        except requests.exceptions.RequestException as e:
            print(f"è«‹æ±‚éŒ¯èª¤: {e}")
            return {"error": "request_error", "message": str(e)}
        except json.JSONDecodeError as e:
            print(f"JSON è§£æéŒ¯èª¤: {e}")
            print(f"åŸå§‹å›æ‡‰: {response.text[:500]}...")
            return {"error": "json_error", "message": str(e)}


def main():
    """ä¸»ç¨‹å¼"""
    # API è¨­å®š
    BASE_URL = "https://llm.cubeapp945566.work"
    API_KEY = "sk-local-123"
    
    # å»ºç«‹ API å®¢æˆ¶ç«¯
    api = LLMAPI(BASE_URL, API_KEY)
    
    # æ¸¬è©¦è¨Šæ¯
    test_messages = [
        {"role": "user", "content": "è«‹ç”¨10å€‹å­—ä»‹ç´¹ä½ è‡ªå·±"}
    ]
    
    print("=" * 50)
    print("LLM API å‘¼å«æ¸¬è©¦")
    print("=" * 50)
    
    # ç™¼é€è«‹æ±‚
    start_time = time.time()
    result = api.chat_completion(
        messages=test_messages,
        model="gpt-oss-120b",
        temperature=0.7,
        stream=False
    )
    end_time = time.time()
    
    print("\n" + "=" * 50)
    print("æ¸¬è©¦çµæœæ‘˜è¦")
    print("=" * 50)
    print(f"è«‹æ±‚è€—æ™‚: {end_time - start_time:.2f} ç§’")
    
    if "error" not in result:
        print("âœ… API å‘¼å«æˆåŠŸ")
        if "choices" in result and len(result["choices"]) > 0:
            content = result["choices"][0]["message"]["content"]
            print(f"AI å›æ‡‰: {content}")
    else:
        print(f"âŒ API å‘¼å«å¤±æ•—: {result.get('message', 'æœªçŸ¥éŒ¯èª¤')}")


if __name__ == "__main__":
    main()
